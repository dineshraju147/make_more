{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-10T22:56:13.038032Z",
     "start_time": "2025-07-10T22:56:12.861166Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "from Transformers.NanoGPT import block_size\n",
    "%matplotlib inline\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:31:26.746689Z",
     "start_time": "2025-07-11T03:31:26.727654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ],
   "id": "8a2b89a8ca48a0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T22:57:09.112801Z",
     "start_time": "2025-07-10T22:57:09.104100Z"
    }
   },
   "cell_type": "code",
   "source": "len(words)",
   "id": "b3d1244c552afb16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T22:57:28.990329Z",
     "start_time": "2025-07-10T22:57:28.983769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ],
   "id": "fb6993bd6009f0fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:52:10.180458Z",
     "start_time": "2025-07-11T01:52:09.950771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 3\n",
    "context = [0] * block_size\n",
    "\n",
    "X , Y = [] , []\n",
    "\n",
    "for w in words:\n",
    "    # print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # print(\"X:\" , X ,  \"Y:\" , Y)\n",
    "        # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ],
   "id": "e9260b3b47607686",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:52:11.958772Z",
     "start_time": "2025-07-11T01:52:11.952918Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape,X.dtype,  Y.shape, Y.dtype",
   "id": "bea1a2397270b17e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lets Build our Embedding Table (Look Up Table) for our Character level model",
   "id": "df95833683a67dd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Now we have make our dataset to predict the probability of nxt word. lets put these into neural network layer. Before moving to feeding, we need to reduce our 27 char we have into lower dimensions --> Two dim\n",
    "-- As we are proceeding to reimplement the architecture by A Neural Probabilistic Language Model {A Neural Probabilistic Language Model}\n",
    "-- they have implemented via 17000  words in our case we are proceeding with char level model so we have 27 dim\n",
    "-- They compressed 17000 dim to 30 dim , So lets compress the dimension to 2."
   ],
   "id": "fb69259d7bc80e3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:25:35.744766Z",
     "start_time": "2025-07-10T23:25:35.735925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Look Up Table : -- C\n",
    "# by the way these are the weights which we adjust during the back-propagation\n",
    "C = torch.rand(27, 2) # intialize random numbers for Look up table\n",
    "C"
   ],
   "id": "e27fe39fcef985ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2524, 0.6784],\n",
       "        [0.9725, 0.1287],\n",
       "        [0.8615, 0.9255],\n",
       "        [0.1698, 0.2375],\n",
       "        [0.5656, 0.2844],\n",
       "        [0.8355, 0.7482],\n",
       "        [0.2397, 0.1919],\n",
       "        [0.9909, 0.7481],\n",
       "        [0.1026, 0.3385],\n",
       "        [0.2130, 0.6969],\n",
       "        [0.1042, 0.1538],\n",
       "        [0.2023, 0.2267],\n",
       "        [0.9852, 0.0523],\n",
       "        [0.2429, 0.0680],\n",
       "        [0.3577, 0.5322],\n",
       "        [0.5342, 0.9979],\n",
       "        [0.9999, 0.7068],\n",
       "        [0.1383, 0.0674],\n",
       "        [0.8196, 0.4099],\n",
       "        [0.5432, 0.4103],\n",
       "        [0.6175, 0.0526],\n",
       "        [0.7107, 0.2023],\n",
       "        [0.6299, 0.5623],\n",
       "        [0.6084, 0.3684],\n",
       "        [0.6064, 0.5983],\n",
       "        [0.3008, 0.9703],\n",
       "        [0.0621, 0.8364]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:25:42.446670Z",
     "start_time": "2025-07-10T23:25:42.438661Z"
    }
   },
   "cell_type": "code",
   "source": "C[5]",
   "id": "db8458ec2bf1bac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8355, 0.7482])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:32:36.208547Z",
     "start_time": "2025-07-10T23:32:36.191489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we start to generate the embeddings of our chars\n",
    "# lets say we need to encode num 5 in 27 numbers\n",
    "# why we need to do this,\n",
    "# ----- in order to get the char embeddings we have two dim for each char, so we're extracting the embedding by\n",
    "# matrix multiplying  one hot * Our Look up table (C)\n",
    "F.one_hot(torch.tensor([5 ]), 27).dtype"
   ],
   "id": "1a6dd5decb8ba604",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:33:18.871307Z",
     "start_time": "2025-07-10T23:33:18.856905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now by doing this way we can pluck the relevent char embedding to feed to NN\n",
    "# this is the one way, but torch offers very easy way to handle this , we can do this direclty by mentioning the indexs on the tensor itself\n",
    "F.one_hot(torch.tensor([5 ]), 27).float() @ C\n"
   ],
   "id": "83959bdef3d59ff9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8355, 0.7482]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:37:12.755033Z",
     "start_time": "2025-07-10T23:37:12.740086Z"
    }
   },
   "cell_type": "code",
   "source": "C[torch.tensor([5, 6, 7,7,7  ])]",
   "id": "4de56dbc7ebdb8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8355, 0.7482],\n",
       "        [0.2397, 0.1919],\n",
       "        [0.9909, 0.7481],\n",
       "        [0.9909, 0.7481],\n",
       "        [0.9909, 0.7481]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:44:50.966123Z",
     "start_time": "2025-07-10T23:44:50.962295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we can also give multidim array to get the tables\n",
    "# Now we can get our embeddings for our characters which --> X , C--> (32 , 3) ,(27,2) -> (32, 3, 2)\n",
    "C[X].shape"
   ],
   "id": "cc3bcd43e54a953a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:48:47.314116Z",
     "start_time": "2025-07-10T23:48:47.307805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets check this\n",
    "X[13, 2]"
   ],
   "id": "b06a4de64fe46d01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:49:00.368315Z",
     "start_time": "2025-07-10T23:49:00.357932Z"
    }
   },
   "cell_type": "code",
   "source": "C[X][13, 2]",
   "id": "2ae8b4e2b1fc81bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9725, 0.1287])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:50:16.732969Z",
     "start_time": "2025-07-10T23:50:16.725223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# its how its embed on the 3 dim array\n",
    "C[1]"
   ],
   "id": "a0c392045b8e9d2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9725, 0.1287])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T23:51:20.084770Z",
     "start_time": "2025-07-10T23:51:20.074702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# so this our emb matrix for our chars\n",
    "embed = C[X]\n",
    "embed.shape"
   ],
   "id": "e8df23d4156cb5f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:09:00.695051Z",
     "start_time": "2025-07-11T00:09:00.681845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets start with the first layer of our MLP\n",
    "W1 = torch.randn(6, 100)\n",
    "b1 = torch.randn(100)"
   ],
   "id": "cee9dab98db78ff2",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:10:15.214527Z",
     "start_time": "2025-07-11T00:10:15.178095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to modify weights we need to follow W.X+b\n",
    "# we cant do it directly\n",
    "# since we have our embed shape as (32, 3, 2) which cant be multiply with [6,100]\n",
    "# in order to do that we need to change our embed matrix into (32, 6)\n",
    "W1 @ embed +b1"
   ],
   "id": "7e11a2a71eee375b",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [32, 100] but got: [32, 3].",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[46]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# to modify weights we need to follow W.X+b\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# we cant do it directly \u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mW1\u001B[49m\u001B[43m \u001B[49m\u001B[43m@\u001B[49m\u001B[43m \u001B[49m\u001B[43membed\u001B[49m +b1\n",
      "\u001B[31mRuntimeError\u001B[39m: Expected size for first two dimensions of batch2 tensor to be: [32, 100] but got: [32, 3]."
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:15:42.338779Z",
     "start_time": "2025-07-11T00:15:42.330591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets concat the embed matrix into 32, 6 via 2 nd dim\n",
    "torch.cat([embed[:, 0,:], embed[:,1,:], embed[:,2,:]], dim=1)"
   ],
   "id": "204bbd1d01ce8d1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.8355, 0.7482],\n",
       "        [0.2524, 0.6784, 0.8355, 0.7482, 0.2429, 0.0680],\n",
       "        [0.8355, 0.7482, 0.2429, 0.0680, 0.2429, 0.0680],\n",
       "        [0.2429, 0.0680, 0.2429, 0.0680, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.5342, 0.9979],\n",
       "        [0.2524, 0.6784, 0.5342, 0.9979, 0.9852, 0.0523],\n",
       "        [0.5342, 0.9979, 0.9852, 0.0523, 0.2130, 0.6969],\n",
       "        [0.9852, 0.0523, 0.2130, 0.6969, 0.6299, 0.5623],\n",
       "        [0.2130, 0.6969, 0.6299, 0.5623, 0.2130, 0.6969],\n",
       "        [0.6299, 0.5623, 0.2130, 0.6969, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.9725, 0.1287, 0.6299, 0.5623],\n",
       "        [0.9725, 0.1287, 0.6299, 0.5623, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2130, 0.6969],\n",
       "        [0.2524, 0.6784, 0.2130, 0.6969, 0.5432, 0.4103],\n",
       "        [0.2130, 0.6969, 0.5432, 0.4103, 0.9725, 0.1287],\n",
       "        [0.5432, 0.4103, 0.9725, 0.1287, 0.8615, 0.9255],\n",
       "        [0.9725, 0.1287, 0.8615, 0.9255, 0.8355, 0.7482],\n",
       "        [0.8615, 0.9255, 0.8355, 0.7482, 0.9852, 0.0523],\n",
       "        [0.8355, 0.7482, 0.9852, 0.0523, 0.9852, 0.0523],\n",
       "        [0.9852, 0.0523, 0.9852, 0.0523, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.5432, 0.4103],\n",
       "        [0.2524, 0.6784, 0.5432, 0.4103, 0.5342, 0.9979],\n",
       "        [0.5432, 0.4103, 0.5342, 0.9979, 0.9999, 0.7068],\n",
       "        [0.5342, 0.9979, 0.9999, 0.7068, 0.1026, 0.3385],\n",
       "        [0.9999, 0.7068, 0.1026, 0.3385, 0.2130, 0.6969],\n",
       "        [0.1026, 0.3385, 0.2130, 0.6969, 0.9725, 0.1287]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:16:57.242262Z",
     "start_time": "2025-07-11T00:16:57.236038Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cat([embed[:,0,:], embed[:,1,:], embed[:,2,:]], dim=1).shape",
   "id": "d60819fc85ca605d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:19:55.540800Z",
     "start_time": "2025-07-11T00:19:55.527972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is fine for three block size but for more block size we can use torch.unbind\n",
    "# which gives == embed[:,0,:], embed[:,1,:], embed[:,2,:]\n",
    "torch.unbind(embed,1)  # 1, IS DIM"
   ],
   "id": "f47e908d4f2607df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.8355, 0.7482],\n",
       "         [0.2429, 0.0680],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.5342, 0.9979],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.6299, 0.5623],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.5432, 0.4103],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.8615, 0.9255],\n",
       "         [0.8355, 0.7482],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.5432, 0.4103],\n",
       "         [0.5342, 0.9979],\n",
       "         [0.9999, 0.7068],\n",
       "         [0.1026, 0.3385]]),\n",
       " tensor([[0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.8355, 0.7482],\n",
       "         [0.2429, 0.0680],\n",
       "         [0.2429, 0.0680],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.5342, 0.9979],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.6299, 0.5623],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.6299, 0.5623],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.5432, 0.4103],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.8615, 0.9255],\n",
       "         [0.8355, 0.7482],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.5432, 0.4103],\n",
       "         [0.5342, 0.9979],\n",
       "         [0.9999, 0.7068],\n",
       "         [0.1026, 0.3385],\n",
       "         [0.2130, 0.6969]]),\n",
       " tensor([[0.2524, 0.6784],\n",
       "         [0.8355, 0.7482],\n",
       "         [0.2429, 0.0680],\n",
       "         [0.2429, 0.0680],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.5342, 0.9979],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.6299, 0.5623],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.6299, 0.5623],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.5432, 0.4103],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.8615, 0.9255],\n",
       "         [0.8355, 0.7482],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.9852, 0.0523],\n",
       "         [0.9725, 0.1287],\n",
       "         [0.2524, 0.6784],\n",
       "         [0.5432, 0.4103],\n",
       "         [0.5342, 0.9979],\n",
       "         [0.9999, 0.7068],\n",
       "         [0.1026, 0.3385],\n",
       "         [0.2130, 0.6969],\n",
       "         [0.9725, 0.1287]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:21:57.225437Z",
     "start_time": "2025-07-11T00:21:57.219450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we can concate this is same we have on top\n",
    "torch.cat(torch.unbind(embed,1), 1).shape\n"
   ],
   "id": "ec5eea4cdf165b3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:27:26.764464Z",
     "start_time": "2025-07-11T00:27:26.744224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# how can do this operation even more efficient way as : with the torch.view() method\n",
    "# which will not effect the storage but it changes the shape of dim in what shape we need to view the storage\n",
    "embed.view(32,6) # just as simple as that and it concats the way actually we want in Dim=1\n"
   ],
   "id": "7cdde9506b4c3636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.8355, 0.7482],\n",
       "        [0.2524, 0.6784, 0.8355, 0.7482, 0.2429, 0.0680],\n",
       "        [0.8355, 0.7482, 0.2429, 0.0680, 0.2429, 0.0680],\n",
       "        [0.2429, 0.0680, 0.2429, 0.0680, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.5342, 0.9979],\n",
       "        [0.2524, 0.6784, 0.5342, 0.9979, 0.9852, 0.0523],\n",
       "        [0.5342, 0.9979, 0.9852, 0.0523, 0.2130, 0.6969],\n",
       "        [0.9852, 0.0523, 0.2130, 0.6969, 0.6299, 0.5623],\n",
       "        [0.2130, 0.6969, 0.6299, 0.5623, 0.2130, 0.6969],\n",
       "        [0.6299, 0.5623, 0.2130, 0.6969, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.9725, 0.1287, 0.6299, 0.5623],\n",
       "        [0.9725, 0.1287, 0.6299, 0.5623, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2130, 0.6969],\n",
       "        [0.2524, 0.6784, 0.2130, 0.6969, 0.5432, 0.4103],\n",
       "        [0.2130, 0.6969, 0.5432, 0.4103, 0.9725, 0.1287],\n",
       "        [0.5432, 0.4103, 0.9725, 0.1287, 0.8615, 0.9255],\n",
       "        [0.9725, 0.1287, 0.8615, 0.9255, 0.8355, 0.7482],\n",
       "        [0.8615, 0.9255, 0.8355, 0.7482, 0.9852, 0.0523],\n",
       "        [0.8355, 0.7482, 0.9852, 0.0523, 0.9852, 0.0523],\n",
       "        [0.9852, 0.0523, 0.9852, 0.0523, 0.9725, 0.1287],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.2524, 0.6784],\n",
       "        [0.2524, 0.6784, 0.2524, 0.6784, 0.5432, 0.4103],\n",
       "        [0.2524, 0.6784, 0.5432, 0.4103, 0.5342, 0.9979],\n",
       "        [0.5432, 0.4103, 0.5342, 0.9979, 0.9999, 0.7068],\n",
       "        [0.5342, 0.9979, 0.9999, 0.7068, 0.1026, 0.3385],\n",
       "        [0.9999, 0.7068, 0.1026, 0.3385, 0.2130, 0.6969],\n",
       "        [0.1026, 0.3385, 0.2130, 0.6969, 0.9725, 0.1287]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:28:32.866951Z",
     "start_time": "2025-07-11T00:28:32.857457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we can check this :\n",
    "embed.view(32,6)  == torch.cat(torch.unbind(embed,1), 1)"
   ],
   "id": "e1240aa3ff62467a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:30:40.405105Z",
     "start_time": "2025-07-11T00:30:40.393843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# so we can perform our first layer multiplications, Now its actually work\n",
    "embed.view(32,6) @ W1 +b1"
   ],
   "id": "4282c282ec26fc6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:32:11.666714Z",
     "start_time": "2025-07-11T00:32:11.660168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for not hard coding\n",
    "h = embed.view(embed.shape[0],6) @ W1 +b1  # we can do  embed.shape[0] == -1\n",
    "h.shape"
   ],
   "id": "33bb25efcaf8170d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### we have the  values for layer 2 of our MLP  [32,100],\n",
    "#### lets introduce the non-Linearity to our layer\n",
    "#####  idx --> Look_up_table[idx] --> [32, 6] (inputs of mlp) -- emb*w1+b --> [6, 100] --> tanh(layer2)"
   ],
   "id": "5d216106dbd00896"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:38:15.537497Z",
     "start_time": "2025-07-11T00:38:15.525667Z"
    }
   },
   "cell_type": "code",
   "source": "h = torch.tanh(embed.view(embed.shape[0],6) @ W1 +b1 )",
   "id": "787016a0372f0b4",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:38:22.725156Z",
     "start_time": "2025-07-11T00:38:22.719754Z"
    }
   },
   "cell_type": "code",
   "source": "h.shape",
   "id": "13043399e0508bc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:41:36.069376Z",
     "start_time": "2025-07-11T00:41:36.064752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We need to make sure the broadcasting rules while calculations of tensors\n",
    "# in this case we are adding W1 + b\n",
    "# which are  [32, 100] + [100]\n",
    "# what broadcasting do\n",
    "# 32, 100\n",
    "#  1  , 100    it adds one dim on left which gives a one row of 100 values and adds the same row with 32 rows in w1 (that what we need to have)\n"
   ],
   "id": "28780eda5096f97f",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:45:22.602669Z",
     "start_time": "2025-07-11T00:45:22.591135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finally we are here to final layer of our MLP\n",
    "# we need to 100 ---> 27(our char ints) --- these are vary by vocabulary\n",
    "W2 = torch.randn(100, 27)\n",
    "b2 = torch.rand(27)"
   ],
   "id": "80491fe98ed217",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:46:18.925593Z",
     "start_time": "2025-07-11T00:46:18.918211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# so our logits will be h*W2 + b2\n",
    "\n",
    "logits = h @ W2 +b2\n",
    "logits.shape"
   ],
   "id": "6885b53a0160bc83",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:52:50.341688Z",
     "start_time": "2025-07-11T00:52:50.331603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we got the logits of our final layer we now need to get the softmax values of those logits\n",
    "# to get the probabilites\n",
    "# as we do in our last part\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)  # these are the predictions for the next word"
   ],
   "id": "fcada66a7810f39b",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:52:59.516420Z",
     "start_time": "2025-07-11T00:52:59.510546Z"
    }
   },
   "cell_type": "code",
   "source": "prob.shape",
   "id": "1567a1b515fbd280",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:53:18.332133Z",
     "start_time": "2025-07-11T00:53:18.322330Z"
    }
   },
   "cell_type": "code",
   "source": "prob[0].sum()",
   "id": "9c6a4684b1d1f85f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:58:37.142242Z",
     "start_time": "2025-07-11T00:58:37.130269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# also  we have actual values Y\n",
    "Y"
   ],
   "id": "82d6d96285055881",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:02:08.352424Z",
     "start_time": "2025-07-11T01:02:08.337495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now lets see how was our model predicted these chars values\n",
    "prob[torch.arange(32), Y]  # these are predicted probs for actual values which are not that good"
   ],
   "id": "d166c4e248ebfa91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.6524e-08, 6.4011e-03, 7.8358e-06, 6.2319e-06, 6.0953e-12, 2.1791e-09,\n",
       "        4.8655e-10, 5.5937e-09, 2.0430e-06, 4.9461e-07, 1.2399e-04, 2.3388e-08,\n",
       "        2.4564e-06, 1.5236e-01, 3.4163e-03, 1.5080e-07, 2.7459e-06, 1.7223e-04,\n",
       "        8.7097e-05, 1.5270e-08, 5.6583e-08, 1.9838e-06, 7.7026e-08, 5.3460e-05,\n",
       "        7.0146e-10, 2.1474e-04, 1.0187e-08, 4.6979e-09, 2.8162e-08, 2.3356e-11,\n",
       "        9.0008e-09, 8.6235e-10])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss function",
   "id": "ecc1b38d330b15f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:05:03.625274Z",
     "start_time": "2025-07-11T01:05:03.615059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss # this is loss we need to minimize to predict the correct next word prediction"
   ],
   "id": "9422547475e94ea1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8393)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:52:31.099597Z",
     "start_time": "2025-07-11T01:52:31.094352Z"
    }
   },
   "cell_type": "code",
   "source": "# ------------- > lets make this more cleaner",
   "id": "317137c8d8f5d059",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:54:52.324463Z",
     "start_time": "2025-07-11T01:54:52.317682Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape,  Y.shape # dataset",
   "id": "8c46eb82bd89844e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:54:53.607519Z",
     "start_time": "2025-07-11T01:54:53.600281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.rand(27, 2 , generator=g)  # look up table\n",
    "W1 = torch.randn((6, 100), generator=g)  ## Layer 1\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)  # layer 2\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ],
   "id": "b272a4435a68a140",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:54:54.872202Z",
     "start_time": "2025-07-11T01:54:54.866208Z"
    }
   },
   "cell_type": "code",
   "source": "sum(p.nelement() for p in parameters) # num of parameters\n",
   "id": "eb20fcb98dbd9aae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Forward Pass",
   "id": "4f182409b1ecfefe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:53:04.851930Z",
     "start_time": "2025-07-11T01:53:04.770075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# emb = C[X]  # (32, 3, 2)\n",
    "# h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "# logits = h @ W2 + b2 # (32, 27)\n",
    "# counts = logits.exp()\n",
    "# prob = counts / counts.sum(1, keepdim=True)\n",
    "# loss = -prob[torch.arange(32), Y].log().mean()\n",
    "# loss\n"
   ],
   "id": "e0c6e6b046ac526d",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [32], [228146]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[145]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m counts = logits.exp()\n\u001B[32m      5\u001B[39m prob = counts / counts.sum(\u001B[32m1\u001B[39m, keepdim=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m loss = -\u001B[43mprob\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m]\u001B[49m.log().mean()\n\u001B[32m      7\u001B[39m loss\n",
      "\u001B[31mIndexError\u001B[39m: shape mismatch: indexing tensors could not be broadcast together with shapes [32], [228146]"
     ]
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:40:29.114221Z",
     "start_time": "2025-07-11T01:40:29.107730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we can calculate the loss even more efficiently with the F.cross_entropy\n",
    "# F.cross_entropy(logits, Y)\n",
    "# why its efficient\n",
    "# 1-- more efficient forward pass\n",
    "# 2-- more efficient back pass\n",
    "# 3-  and things can be numerically well behave\n"
   ],
   "id": "1be6b62b5de9943d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.1065)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:53:33.830586Z",
     "start_time": "2025-07-11T01:53:33.823032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets see an example:\n",
    "# in this it working fine right but what if we have extreme high value in our logits\n",
    "#like [1000, 0, 10 ]\n",
    "logits = torch.tensor([-5, 0, 1, 2])\n",
    "counts = logits.exp()\n",
    "\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ],
   "id": "990c2a5ed5646db4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0625e-04, 8.9976e-02, 2.4458e-01, 6.6484e-01])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:53:35.424900Z",
     "start_time": "2025-07-11T01:53:35.416376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shows nan as exp(1000) --> inf\n",
    "logits = torch.tensor([-5, 0, 1, 1000])\n",
    "\n",
    "counts = logits.exp()\n",
    "print(counts)\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ],
   "id": "ecf36a959229bce7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0067, 1.0000, 2.7183,    inf])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., nan])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:55:00.965932Z",
     "start_time": "2025-07-11T01:55:00.957214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# So how pytorch tackle this in F.cross_entropy\n",
    "# it just subtracts the highest value in the tensor , which gives an efficient way to represent logits\n",
    "# not only this Pytorch. Cross_entropy reduce the calculations of all these exp and counts and finding probs by squeezing them which makes much more easier for backpropagation\n",
    "\n",
    "logits = torch.tensor([-5, 0, 1, 1000]) -1000\n",
    "counts = logits.exp()\n",
    "print(counts)\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ],
   "id": "4848459deccaa273",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:55:02.953736Z",
     "start_time": "2025-07-11T01:55:02.948504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ],
   "id": "1d5598c0a6f1587d",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T02:01:49.590331Z",
     "start_time": "2025-07-11T02:01:49.561380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 100\n",
    "for _ in range(epochs):\n",
    "\n",
    "    # mini batch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[ix]]  # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    # print(loss.item())\n",
    "    # Backward Pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    for p in parameters:\n",
    "        learning_rate = -0.1\n",
    "        p.data += learning_rate * p.grad\n",
    "print(loss.item())"
   ],
   "id": "99fafc85117ea372",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6803760528564453\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T02:01:50.610398Z",
     "start_time": "2025-07-11T02:01:50.538560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb = C[X]  # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "print(loss.item())"
   ],
   "id": "4307dd2cb34a6f5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7324628829956055\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T01:53:58.352204Z",
     "start_time": "2025-07-11T01:53:58.346601Z"
    }
   },
   "cell_type": "code",
   "source": "Y",
   "id": "2eadb2e5fdd9048d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  ..., 26, 24,  0])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 152
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
