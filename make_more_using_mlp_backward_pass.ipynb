{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Make_More V3\n",
    "#### Bulding our own loss.backward()\n"
   ],
   "id": "b9a52b674836080e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:33.264949Z",
     "start_time": "2025-07-18T12:21:33.249434Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "from networkx.classes import non_edges\n",
    "from sympy import hermite_prob\n",
    "from torch import nn\n",
    "# from Transformers.NanoGPT import vocab_size\n",
    "%matplotlib inline\n"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:34.585367Z",
     "start_time": "2025-07-18T12:21:34.570831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ],
   "id": "8a2b89a8ca48a0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:36.118932Z",
     "start_time": "2025-07-18T12:21:36.113826Z"
    }
   },
   "cell_type": "code",
   "source": "len(words)",
   "id": "b3d1244c552afb16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:37.206254Z",
     "start_time": "2025-07-18T12:21:37.197856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ],
   "id": "fb6993bd6009f0fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:39.608671Z",
     "start_time": "2025-07-18T12:21:39.132155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 3\n",
    "context = [0] * block_size\n",
    "\n",
    "\n",
    "def build_datasets(words):\n",
    "    X , Y = [] , []\n",
    "\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print(\"X:\" , X ,  \"Y:\" , Y)\n",
    "            # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_datasets(words[:n1])  # 80% of Xtr\n",
    "Xdev, Ydev = build_datasets(words[n1:n2]) # 10%\n",
    "Xte, Yte = build_datasets(words[n2:]) # 10%\n",
    "\n",
    "print(f'Xtr: {Xtr.shape}, Ytr: {Ytr.shape}')\n",
    "print(f'Xdev: {Xdev.shape}, Ydev: {Ydev.shape}')\n",
    "print(f'Xte: {Xte.shape}, Yte: {Yte.shape}')\n",
    "\n"
   ],
   "id": "e9260b3b47607686",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr: torch.Size([182594, 3]), Ytr: torch.Size([182594])\n",
      "Xdev: torch.Size([22846, 3]), Ydev: torch.Size([22846])\n",
      "Xte: torch.Size([22706, 3]), Yte: torch.Size([22706])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:41.118017Z",
     "start_time": "2025-07-18T12:21:41.114064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function Used to comparing manual gradients with Pytorch Gradients\n",
    "def cmp(s, dt , t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ],
   "id": "99d2fe197c60b428",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:42.783881Z",
     "start_time": "2025-07-18T12:21:42.773145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "# -------------Embeddings --------------------\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ],
   "id": "14d868e8a0c468c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:45.343071Z",
     "start_time": "2025-07-18T12:21:45.336724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ],
   "id": "2a00d2eda1eca708",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:21:46.949044Z",
     "start_time": "2025-07-18T12:21:46.945701Z"
    }
   },
   "cell_type": "code",
   "source": "Xb.shape",
   "id": "d9a59467fd0d9c4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T18:42:44.682171Z",
     "start_time": "2025-07-18T18:42:44.671275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "# ---------------Getting the Embeddings of character contex-------------\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(Xb.shape[0],-1) # concatenate the vectors\n",
    "\n",
    "# ----------------Linear Layer 1----------------------\n",
    "hprebn = embcat @ W1 +b1\n",
    "\n",
    "#---------------- Batch Norm Layer -------------------\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff*bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# -----Non-linearity----------------------\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "#---------Linear Layer 2 (27 neurons for 27 char)----------\n",
    "logits = h @ W2 + b2\n",
    "print(f'Logits:{logits.shape}')\n",
    "# ----------------cross entropy loss (same as F.cross_entropy(logits, Yb))----\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtracting logits from max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts*counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "# calculating loss from log probs\n",
    "loss = -logprobs[range(n), Yb].mean()  # this line plucks the correct next character log probs values as in Yb(index)\n",
    "print(f'Manually Calculated Loss:{loss}')\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "print(f'Pytorch calculated Loss :{loss}')"
   ],
   "id": "1e3cbfa313397566",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:torch.Size([32, 27])\n",
      "Manually Calculated Loss:3.296250343322754\n",
      "Pytorch calculated Loss :3.296250343322754\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T18:42:46.779065Z",
     "start_time": "2025-07-18T18:42:46.773923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'dlogits :{dlogits.shape}')\n",
    "print(f'H shape: {h.shape}')\n",
    "print(f'W2 shape: {W2.shape}')\n",
    "print(f'b2 shape: {b2.shape}')"
   ],
   "id": "e6ce48b24fd057ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits :torch.Size([32, 27])\n",
      "H shape: torch.Size([32, 64])\n",
      "W2 shape: torch.Size([64, 27])\n",
      "b2 shape: torch.Size([27])\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T18:42:48.019066Z",
     "start_time": "2025-07-18T18:42:48.013444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------ hpreact = bngain * bnraw + bnbias ------------\n",
    "print(f'hpreact :{hpreact.shape}')\n",
    "print(f'bngain :{bngain.shape}')\n",
    "print(f'bnraw : {bnraw.shape}')\n",
    "print(f'bnbias :{bnbias.shape}')"
   ],
   "id": "2b6524fe4a5f6fda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact :torch.Size([32, 64])\n",
      "bngain :torch.Size([1, 64])\n",
      "bnraw : torch.Size([32, 64])\n",
      "bnbias :torch.Size([1, 64])\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T03:26:13.658305Z",
     "start_time": "2025-07-18T03:26:13.631431Z"
    }
   },
   "cell_type": "code",
   "source": "#\n",
   "id": "d7ba07a2cf7e2e69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T18:42:49.739923Z",
     "start_time": "2025-07-18T18:42:49.731827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------backprop : logits = h @ W2 + b2 ---------------\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)"
   ],
   "id": "ec818da2b4affc32",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T18:43:11.600153Z",
     "start_time": "2025-07-18T18:43:11.591285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------bnraw = bndiff*bnvar_inv --------\n",
    "print(bnraw.shape)\n",
    "print(bndiff.shape)\n",
    "print(bnvar.shape)\n",
    "print(bnvar_inv.shape)\n",
    "# -- dbnraw/dbndiff = bnvar_inv*bnraw\n",
    "dbndiff = bnvar_inv*dbnraw\n",
    "print(dbndiff.shape)\n",
    "\n",
    "#------bnvar_inv = (bnvar**2 + 1e-5)**-0.5 --------\n",
    "dbnvar =  -0.5*(bnvar + 1e-5)**-1.5\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "fa9a790393a5e7bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T00:50:48.153024Z",
     "start_time": "2025-07-18T00:50:47.974024Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1126146e0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 60,
   "source": "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))",
   "id": "aac4e3ed9cd4835d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T19:03:16.093441Z",
     "start_time": "2025-07-18T19:03:16.083575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------- Backpropagating through the whole thing manually\n",
    "# ------- Backprop through exactly all variables\n",
    "# ------- As we defined in the forward pass one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "#  probs ---> log(probs)------> logprobs ====> dprobs = 1/probs*d(output)\n",
    "dprobs = (1.0/probs)*dlogprobs # chain rule\n",
    "dcounts_sum_inv = (counts*dprobs).sum(1, keepdim=True) # summation is due to the replication of counts_sum_inv\n",
    "# ----- Since the shape of counts and counts_sum_inv are not equal there is a replication of counts_sum_inv to\n",
    "# all of columns\n",
    "# C = a*b tensors ====> dc/da = a * chainrule---------------\n",
    "# a[3x3] , b[3x1]\n",
    "# a11*b1  a12*b1 a13*b1 # here b is replicating along the all columns of a\n",
    "# a21*b2  a22*b2 a23*b2 # so for this in backward pass while calculating gradient if same node gives two outputs\n",
    "# a31*b3 a32*b3  a33*b3 # the gradients have to summ at that node\n",
    "dcounts = counts_sum_inv * dprobs # counts node is using two branches so we need to sum the gradients\n",
    "dcounts_sum = -(counts_sum**-2)*dcounts_sum_inv\n",
    "# ---- counts.sum(1, keepdim=True) here we are using sum for row summing\n",
    "#  a11 a12 a13 => b1 = a11 + a12 + a13\n",
    "#  a21 a22 a23 => b2 = a21 + a22 + a23\n",
    "#  a31 a32 a33 => b2 = a31 + a32 + a33\n",
    "dcounts += torch.ones_like(counts)*dcounts_sum\n",
    "dnorm_logits = counts*dcounts\n",
    "# ---norm_logits = logits - logit_maxes   the shape is not same (logit maxes has [32, 1] which is broadcasting 27 times\n",
    "# we have to encounter this as we do in the dcounts_sum_inv_\n",
    "# c11 c12 c13 = a11 a12 a13  - b1\n",
    "# c21 c22 c23 = a21 a22 a23  - b2 # so dlogits =  1* chain_rule ==dnorm_logits\n",
    "# c31 c32 c33 = a31 a32 a33  - b3\n",
    "dlogits = dnorm_logits\n",
    "dlogit_maxes =  -(dnorm_logits).sum(1, keepdim=True)\n",
    "# -------------- logits.max(1, keepdim=True)---------\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1])*dlogit_maxes\n",
    "# --------backprop : logits = h @ W2 + b2 ---------------\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "# --------- h = torch.tanh(hpreact) --------------- dh/d(z) = 1 - (tanh(z))**2(chainrule) === z= hpreact\n",
    "dhpreact = (1- h**2)*dh\n",
    "# --------------------------hpreact = bngain * bnraw + bnbias ------------------------\n",
    "dbngain = (bnraw*dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = (bngain*dhpreact)\n",
    "dbnbias = (dhpreact).sum(0, keepdim=True)\n",
    "# -----------bnraw = bndiff*bnvar_inv -----------------\n",
    "dbndiff = bnvar_inv*dbnraw\n",
    "dbnvar_inv = (bndiff*dbnraw).sum(0, keepdim=True)\n",
    "\n",
    "#------bnvar_inv = (bnvar**2 + 1e-5)**-0.5 --------\n",
    "dbnvar =  (-0.5*(bnvar + 1e-5)**-1.5)* dbnvar_inv\n",
    "# Note: When we have a tensor.Sum() in forward pass, => turns to a replication with broadcasting in the backward pass\n",
    "# Conversely, When there is a replication due broadcast in forward pass => in backward we are going to sum the values\n",
    "\n",
    "#------------ bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) --------------------\n",
    "# example :\n",
    "# a11 a12\n",
    "# a21 a22\n",
    "# b1  b2\n",
    "# b1 = 1/(n-1)*(a11+ a21)\n",
    "# b2 = 1/(n-1)*(a12 + a22)\n",
    "dbndiff2 = 1/(n-1)*torch.ones_like(bndiff2)*dbnvar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "# cmp('bndiff', dbndiff, bndiff)\n",
    "# cmp('bnmeani', dbnmeani, bnmeani)\n",
    "# cmp('hprebn', dhprebn, hprebn)\n",
    "# cmp('embcat', dembcat, embcat)\n",
    "# cmp('W1', dW1, W1)\n",
    "# cmp('b1', db1, b1)\n",
    "# cmp('emb', demb, emb)\n",
    "# cmp('C', dC, C)"
   ],
   "id": "d7bdb8e97c68bfa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: False | approximate: True  | maxdiff: 4.190951585769653e-09\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48751dc9a126cac0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
